{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTRUCTIONS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1.  The assignment contains four questions. A few bonus questions are mentioned. \n",
    "2.   This assignment is due on **6th Feb, 23:59 **(**No Further extensions**).\n",
    "3.   Assignment must be implemented in Python 3 only.\n",
    "4.   You are allowed to use libraries for data preprocessing (numpy, pandas etc) and for evaluation metrics, data visualization (matplotlib etc.).\n",
    "5.   You will be evaluated not just on the overall performance of the model and also on the experimentation with hyper parameters, data prepossessing techniques etc.\n",
    "6.   The report file must be a well documented jupyter notebook, explaining the experiments you have performed, evaluation metrics and corresponding code. The code must run and be able to reproduce the accuracies, figures/graphs etc.\n",
    "7.   For all the questions, you must create a train-validation data split and test the hyperparameter tuning on the validation set. Your jupyter notebook must reflect the same.\n",
    "8.   Any attempts at **plagiarism will be penalized heavily**.\n",
    "9.   Make sure you run and save your notebooks before submission.\n",
    "10.  For question 3 of the Decision Trees section, output your model's depth first traversal into ```outputimp.txt``` and submit it along with the ipynb file.\n",
    "10. Naming convention for the ipynb file is ```<roll_number>_assign1.ipynb```\n",
    "11. Compress your submission files into a zip file with the naming convention: ```<roll_number>_assign1.zip``` and submit in the portal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#**1) REGRESSION**\n",
    "\n",
    "Please find the Diamond Price Prediction Data set https://drive.google.com/drive/folders/1qE1tm3Ke3uotTyv6SUqruI09t-AkcwRK?usp=sharing. \"description.txt\" contains the feature description of data, \"diamonds.csv\" has the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_data(to_drop):\n",
    "    # To read data from diamonds.csv\n",
    "    headers = [\"carat\",\t\"cut\",\"color\",\"clarity\",\"depth\",\"table\",\"price\",\"x\",\"y\",\"z\"]\n",
    "    data = pd.read_csv('diamonds.csv', na_values='?',    \n",
    "             header=None,  names = headers) \n",
    "    data = data.reset_index(drop=True)\n",
    "    data = data.iloc[1:]\n",
    "    cut_dict = {'Fair':1, 'Good':2, 'Very Good':3, 'Premium':4, 'Ideal':5}\n",
    "    color_dict = {'J':1, 'I':2, 'H':3, 'G':4, 'F':5, 'E':6, 'D':7}\n",
    "    clarity_dict = {'I1':1, 'SI2':2, 'SI1':3, 'VS2': 4, 'VS1':5, 'VVS2':6, 'VVS1':7, 'IF':8}\n",
    "\n",
    "    create_nums = {'cut' : cut_dict, 'clarity':clarity_dict, 'color':color_dict }\n",
    "\n",
    "    data.replace(create_nums, inplace=True)\n",
    "\n",
    "    data = data.astype(np.float64, copy=True)\n",
    "\n",
    "    Y = data['price']\n",
    "    Y = Y.astype(np.float64)\n",
    "\n",
    "    data.drop(labels=to_drop, axis=1, inplace=True)\n",
    "    # TRAIN TEST SPLIT\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data,  Y, test_size=0.20, random_state=40, shuffle=True)\n",
    "    X_train = np.array(X_train[:30000])  # sub-sampling the data as my machine cannot handle all of it.\n",
    "    Y_train = np.array(Y_train[:30000])\n",
    "    X_test = np.array(X_test[:6000])\n",
    "    Y_test = np.array(Y_test[:6000])\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR METRICS\n",
    "def RSME(Y, Y_hat):\n",
    "    # Assumed that Y and Y_hat are one dimensional array\n",
    "    print('RSME metric : ', end='')\n",
    "    Y = np.array(Y)\n",
    "    Y_hat = np.array(Y_hat)\n",
    "    return np.sqrt(np.mean((Y - Y_hat)**2))/Y.shape[0]\n",
    "\n",
    "def MSE(Y, Y_hat):\n",
    "    # Assumed that Y and Y_hat are one dimensional array\n",
    "    print('MSE metric : ', end='')\n",
    "    Y = np.array(Y)\n",
    "    Y_hat = np.array(Y_hat)\n",
    "    return np.mean((Y - Y_hat)**2)/Y.shape[0]\n",
    "\n",
    "def MAE(Y, Y_hat):\n",
    "    # Assumed that Y and Y_hat are one dimensional array\n",
    "    print('MAE metric : ', end='')\n",
    "    Y = np.array(Y)\n",
    "    Y_hat = np.array(Y_hat)\n",
    "    return np.mean(np.abs(Y - Y_hat))/Y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_mean(X):\n",
    "    return np.mean(X, axis=0) # take mean along columns\n",
    "\n",
    "def give_Variance(X):\n",
    "    return np.var(X, axis=0) # take variance along the columns\n",
    "\n",
    "def covariance_matrix(X):\n",
    "    return np.cov(X.T)  # gives the covariance of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN Regression [Diamond Price Prediction Dataset]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. a) Build a knn regression algorithm [using only python from scratch] to predict the price of diamonds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for knn regression\n",
    "class KNNRegression:\n",
    "    def __init__(self, data=None, Y=None):\n",
    "        self.data = data  # the data is preprocessed already, normalized(if it is required), etc, numpy array\n",
    "        self.Y = data # numpy array\n",
    "    \n",
    "    def train(self, data, Y):\n",
    "        self.data = data\n",
    "        self.Y = Y\n",
    "        \n",
    "    def give_dist(self, X, Y, p=2):\n",
    "        dist = np.sum(np.abs(X - Y) ** p)\n",
    "        if p == 2:\n",
    "            return math.sqrt(dist)\n",
    "        else:\n",
    "            return dist\n",
    "    def dist_matrix_manhattan(self, X_test):\n",
    "        num_test = X_test.shape[0]\n",
    "        num_train = self.data.shape[0]\n",
    "        dist_mat = np.zeros((num_test, num_train))\n",
    "        for i in range(num_test):\n",
    "            dist_mat[i, :] = np.sum(np.abs(self.data - X_test[i, :]), axis=1)\n",
    "        return dist_mat\n",
    "        \n",
    "    def dist_matrix(self, X):\n",
    "        dists = -2 * np.dot(X, self.data.T) + np.sum(self.data**2, axis=1) + np.sum(X**2, axis=1)[:, np.newaxis]\n",
    "        return dists\n",
    "\n",
    "    def do_regression(self, dist_mat, k, p=2):\n",
    "        if p > 2 or p <= 0:\n",
    "            raise NotImplementedError('p can only take two values')\n",
    "        indices = np.argpartition(dist_mat, k)\n",
    "        indices = indices[:, :k]\n",
    "        values = np.take(self.Y, indices)\n",
    "        return np.mean(values, axis=1)  # take average along the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000,)\n",
      "RSME metric : 0.24426404341630936\n",
      "r2 score is :- 0.8682832208462565\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = give_data(['price', 'cut', 'clarity', 'color', 'depth', 'table'])\n",
    "regressor = KNNRegression()\n",
    "regressor.train(X_train, Y_train)\n",
    "dists = regressor.dist_matrix_manhattan(X_test)\n",
    "predicted = regressor.do_regression(dists, k=7)\n",
    "print(predicted.shape)\n",
    "print(RSME(Y_test, predicted))\n",
    "r2 = r2_score(Y_test, predicted)\n",
    "print('r2 score is :- {a}'.format(a=r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. b) Do we need to normalise data? [If so Does it make any difference?]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000,)\n",
      "RSME metric : 0.24673852650742942\n",
      "r2 score is :- 0.8656010263045751\n"
     ]
    }
   ],
   "source": [
    "# NORMALISE DATA\n",
    "mean = give_mean(X_train)\n",
    "var = give_Variance(X_train)\n",
    "X_train -= mean\n",
    "X_train /= var\n",
    "X_test -= mean\n",
    "X_test /= var\n",
    "\n",
    "regressor = KNNRegression()\n",
    "regressor.train(X_train, Y_train)\n",
    "dists = regressor.dist_matrix(X_test)\n",
    "predicted = regressor.do_regression(dists, k=7)\n",
    "print(predicted.shape)\n",
    "print(RSME(Y_test, predicted))\n",
    "r2 = r2_score(Y_test, predicted)\n",
    "print('r2 score is :- {a}'.format(a=r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "Yes, it generally helps, but in this specific example it does not make much difference.\n",
    "\n",
    "For classification/Regression algorithms like **KNN**, we measure the **distances** between pairs of samples and these distances are influenced by the measurement units also. For example: Letâ€™s say, we are applying KNN on a data set having 3 features.First feature ranging from 1-10, second from 1-20 and the last one ranging from 1-1000. In this case, most of the clusters will be generated based on the last feature as the difference between 1 to 10 and 1-20 are smaller as compared to 1-1000. To avoid this mis-classification or value prediction, we should normalize the feature variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan Distance\n",
      "RSME metric : 0.24371112382925386\n",
      "r2 score is :- 0.8688788579116036\n",
      "Euclidean Distance\n",
      "RSME metric : 0.24673852650742942\n",
      "r2 score is :- 0.8656010263045751\n"
     ]
    }
   ],
   "source": [
    "# show all the experiments\n",
    "\n",
    "print('Manhattan Distance')\n",
    "dists = regressor.dist_matrix_manhattan(X_test)\n",
    "predicted = regressor.do_regression(dists, k=7)\n",
    "print(RSME(Y_test, predicted))\n",
    "r2 = r2_score(Y_test, predicted)\n",
    "print('r2 score is :- {a}'.format(a=r2))\n",
    "\n",
    "print('Euclidean Distance')\n",
    "dists = regressor.dist_matrix(X_test)\n",
    "predicted = regressor.do_regression(dists, k=7)\n",
    "print(RSME(Y_test, predicted))\n",
    "r2 = r2_score(Y_test, predicted)\n",
    "print('r2 score is :- {a}'.format(a=r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Report Mean Squared Error(MSE), Mean-Absolute-Error(MAE), R-squared (R2) score in a tabular form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score is :- 0.8656010263045751\n",
      "MAE metric : 0.13947561507936507\n",
      "MSE metric : 365.2794027783447\n"
     ]
    }
   ],
   "source": [
    "# report a table\n",
    "r2 = r2_score(Y_test, predicted)\n",
    "print('r2 score is :- {a}'.format(a=r2))\n",
    "print(MAE(Y_test, predicted))\n",
    "print(MSE(Y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
